"""InVEST Coastal Vulnerability"""
import sys
import traceback
import shutil
import time
import os
import math
import logging
import re
import multiprocessing
import zipfile
import pickle

import numpy
from osgeo import gdal
from osgeo import osr
from osgeo import ogr
import pandas
import rtree
import shapely
import shapely.wkb
import shapely.ops
import shapely.speedups
import pygeoprocessing
import taskgraph

from . import utils

LOGGER = logging.getLogger(__name__)

# Wave Watch III data does not cover the planet.  Make sure we don't deal
# with a point that's not in range of said point.  I'm picking 1 degree since
# that's double the diagonal distance between two WWIII points
_MAX_WWIII_DISTANCE = 5.0  # RICH: did you later decide 5 degree is better choice than 1?
_N_FETCH_RAYS = 16


# Create shore points within an AOI 
# Clip the landmass vector path by an AOI
# Could pass AOI to create_shore_points and clip landmass (w/ landmass_rtree)
# Or could clip landmass ahead of time and pass clipped landmass to create_shore_points


# just pass aoi vector to create shore points, for create_raster_from_vector_extents
# then rasterize landmass onto that raster. still need to make sure landmass
# is projected to AOI. Then, wind exposure needs a landmass in AOI projection 
# with a buffer of max-fetch-dist. 

def execute(args):
    """
    
    Parameters:
        workspace_dir (string):
        n_workers:
        wwiii:
        landmass_vector_path:
        aoi_vector_path:
        smallest_feature_size:
        max_fetch_distance:


    """

    output_dir = os.path.join(args['workspace_dir'])
    intermediate_dir = os.path.join(
        args['workspace_dir'], 'intermediate')

    utils.make_directories(
        [output_dir, intermediate_dir])

    work_token_dir = os.path.join(intermediate_dir, '_tmp_work_tokens')
    try:
        n_workers = int(args['n_workers'])
    except (KeyError, ValueError, TypeError):
        # KeyError when n_workers is not present in args
        # ValueError when n_workers is an empty string.
        # TypeError when n_workers is None.
        n_workers = -1  # Single process mode.
    task_graph = taskgraph.TaskGraph(work_token_dir, n_workers)

    # TODO: reproject global inputs (wwiii, global landmass) to AOI SRS, 
    # Before building rtree?
    # Or, build rtrees for global data, then reproject AOI to match,
    # AOI should be small/simple.
    # - wwiii: I project points to match wwiii, for finding nearest.
    # - landmass: project aoi to landmass, clip landmass, then prj land to aoi
    # - relief/bathy: 
    # - continental shelf: 

    wwiii_rtree_path = os.path.join(intermediate_dir, 'wwiii_rtree.dat')
    build_wwiii_rtree_task = task_graph.add_task(
        func=build_wwiii_rtree,
        args=(args['wwiii'], wwiii_rtree_path),
        target_path_list=[wwiii_rtree_path],
        task_name='build_wwiii_rtree')

    landmass_rtree_path = os.path.join(intermediate_dir, 'landmass_rtree.dat')
    build_landmass_rtree_task = task_graph.add_task(
        func=build_feature_bounding_box_rtree,
        args=(args['landmass_vector_path'], landmass_rtree_path),
        target_path_list=[landmass_rtree_path],
        task_name='build_landmass_rtree')

    clipped_landmass_path = os.path.join(
        intermediate_dir, 'clipped_landmass.gpkg')
    clip_landmass_to_aoi_task = task_graph.add_task(
        func=clip_reproject_landmass_to_aoi,
        args=(args['aoi_vector_path'], args['landmass_vector_path'],
              landmass_rtree_path, args['max_fetch_distance'],
              args['smallest_feature_size'], clipped_landmass_path),
        target_path_list=[clipped_landmass_path],
        dependent_task_list=[build_landmass_rtree_task],
        task_name='clip landmass to aoi')

    shore_point_vector_path = os.path.join(
        output_dir, 'shore_points.shp')
    create_shore_points_task = task_graph.add_task(
        func=create_shore_points,
        args=(args['aoi_vector_path'], clipped_landmass_path,
              args['smallest_feature_size'], intermediate_dir,
              shore_point_vector_path),
        target_path_list=[shore_point_vector_path],
        dependent_task_list=[clip_landmass_to_aoi_task, build_wwiii_rtree_task],
        task_name='create shore points')

    exposure_variables_task_list = []

    target_wave_exposure_path = os.path.join(
        intermediate_dir, 'wave_exposure.gpkg')
    wave_exposure_task = task_graph.add_task(
        func=calculate_wave_exposure,
        args=(shore_point_vector_path, args['wwiii'],
              wwiii_rtree_path, target_wave_exposure_path),
        target_path_list=[target_wave_exposure_path],
        dependent_task_list=[create_shore_points_task],
        task_name='calculate wave exposure')
    exposure_variables_task_list.append(wave_exposure_task)

    fetch_point_vector_path = os.path.join(
        intermediate_dir, 'fetch_points.gpkg')
    exposure_variables_task_list.append(task_graph.add_task(
        func=calculate_wind_exposure,
        args=(target_wave_exposure_path, landmass_rtree_path,
              args['landmass_vector_path'], intermediate_dir,
              args['smallest_feature_size'],
              args['max_fetch_distance'], fetch_point_vector_path),
        target_path_list=[fetch_point_vector_path],
        dependent_task_list=[wave_exposure_task],
        task_name='calculate wind exposure'))

    relief_point_vector_path = os.path.join(
        intermediate_dir, 'relief_points.gpkg')
    exposure_variables_task_list.append(task_graph.add_task(
        func=calculate_relief_exposure,
        args=(shore_point_vector_path, args['dem'],
              args['dem_averaging_radius'],
              args['smallest_feature_size'], intermediate_dir,
              relief_point_vector_path),
        target_path_list=[relief_point_vector_path],
        dependent_task_list=[create_shore_points_task],
        task_name='calculate relief exposure'))

    target_habitat_protection_path = os.path.join(
        output_dir, 'habitat_protection.csv')
    exposure_variables_task_list.append(task_graph.add_task(
        func=calculate_habitat_protection,
        args=(shore_point_vector_path,
              args['habitat_table_path'], intermediate_dir,
              target_habitat_protection_path),
        target_path_list=[target_habitat_protection_path],
        dependent_task_list=[create_shore_points_task],
        task_name='calculate habitat protection'))


    # TODO: implement a file_registry dict, because i'm creating this
    # grid_raster_path in two places now.
    grid_raster_path = os.path.join(intermediate_dir, 'grid.tif')
    target_geomorphology_raster_path = os.path.join(
        intermediate_dir, 'final_geomorphology_rank.tif')
    target_pickle_path = os.path.join(intermediate_dir, 'geomorphology.pickle')
    exposure_variables_task_list.append(task_graph.add_task(
        func=calculate_geomorphology_exposure,
        args=(args['geomorphology_vector_path'],
              grid_raster_path, intermediate_dir,
              target_geomorphology_raster_path,
              shore_point_vector_path,
              target_pickle_path),
        target_path_list=[target_geomorphology_raster_path, target_pickle_path],
        dependent_task_list=[create_shore_points_task],
        task_name='calculate geomorphology exposure'))
    
    task_graph.close()
    task_graph.join()


def clip_reproject_landmass_to_aoi(
        aoi_vector_path, landmass_vector_path, landmass_rtree_path,
        max_fetch_distance, smallest_feature_size,
        target_clipped_landmass_path):
    """Clip landmass polygon to AOI.

    # TODO: generalize this function so it just clips to a bbox that is passed in?
    """

    landmass_vector_rtree = rtree.index.Index(
        os.path.splitext(landmass_rtree_path)[0])
    landmass_spatial_reference = osr.SpatialReference()
    landmass_srs_wkt = pygeoprocessing.get_vector_info(
        landmass_vector_path)['projection']
    landmass_spatial_reference.ImportFromWkt(landmass_srs_wkt)
    landmass_vector = gdal.OpenEx(landmass_vector_path, gdal.OF_VECTOR)
    landmass_layer = landmass_vector.GetLayer()

    aoi_vector_info = pygeoprocessing.get_vector_info(
        aoi_vector_path)
    aoi_bounding_box = aoi_vector_info['bounding_box']
    # add the max_fetch_distance to the bounding box so we can use
    # this clipped landmass in the ray casting routine.
    fetch_buffer = max_fetch_distance + smallest_feature_size
    aoi_bounding_box[0] -= fetch_buffer
    aoi_bounding_box[1] -= fetch_buffer
    aoi_bounding_box[2] += fetch_buffer
    aoi_bounding_box[3] += fetch_buffer

    aoi_clipping_box = pygeoprocessing.transform_bounding_box(
        aoi_bounding_box, aoi_vector_info['projection'],
        landmass_srs_wkt, edge_samples=11)
    aoi_clipping_shapely = shapely.geometry.box(*aoi_clipping_box)
    # import pdb; pdb.set_trace()
    gpkg_driver = gdal.GetDriverByName('GPKG')
    clipped_vector = gpkg_driver.Create(
        target_clipped_landmass_path, 0, 0, 0, gdal.GDT_Unknown)
    clipped_layer = clipped_vector.CreateLayer(
        os.path.splitext(os.path.basename(target_clipped_landmass_path))[0],
        landmass_spatial_reference, ogr.wkbPolygon)
    clipped_defn = clipped_layer.GetLayerDefn()

    for feature_id in landmass_vector_rtree.intersection(
            aoi_clipping_box):
        try:
            landmass_feature = landmass_layer.GetFeature(feature_id)
            landmass_shapely = shapely.wkb.loads(
                landmass_feature.GetGeometryRef().ExportToWkb())
            intersection_shapely = aoi_clipping_shapely.intersection(
                landmass_shapely)
            clipped_geometry = ogr.CreateGeometryFromWkt(
                intersection_shapely.wkt)
            clipped_feature = ogr.Feature(clipped_defn)
            clipped_feature.SetGeometry(clipped_geometry)
            clipped_layer.CreateFeature(clipped_feature)
            clipped_feature = None
        except Exception:
            clipped_feature = None
            LOGGER.warn(
                "Couldn't process this intersection %s",
                intersection_shapely)
    clipped_layer.SyncToDisk()
    clipped_layer = None
    clipped_vector = None


def create_shore_points(
        aoi_vector_path, landmass_vector_path, smallest_feature_size,
        workspace_dir, target_shore_point_vector_path):
    """Create points that lie on the coast line of the landmass.

    Parameters:
        landmass_vector_path (string): path to polygon vector representing
            landmass.
        smallest_feature_size (float): smallest feature size to grid a shore
            point on.
        workspace_dir (string): path to a directory that can be created
            during run to hold temporary files.  Will be deleted on successful
            function completion.
        target_shore_point_vector_path (string): path to a point vector that
            will be created and contain points on the shore of the landmass.

    Returns:
        None.

    """
    # create the spatial reference from the base vector
    aoi_vector_info = pygeoprocessing.get_vector_info(aoi_vector_path)
    aoi_spatial_reference = osr.SpatialReference()
    aoi_spatial_reference.ImportFromWkt(aoi_vector_info['projection'])
    aoi_bounding_box = aoi_vector_info['bounding_box']

    grid_raster_path = os.path.join(workspace_dir, 'grid.tif')
    land_mask_raster_path = os.path.join(workspace_dir, 'land_mask.tif')
    convolution_raster_path = os.path.join(
        workspace_dir, 'convolution.tif')
    masked_convolution_raster_path = os.path.join(
        workspace_dir, 'masked_convolution.tif')
    shore_kernel_path = os.path.join(
        workspace_dir, 'shore_kernel.tif')
    shore_raster_path = os.path.join(
        workspace_dir, 'shore_raster.tif')

    esri_shapefile_driver = gdal.GetDriverByName("ESRI Shapefile")

    # this will hold the output sample points on the shore
    target_shore_point_vector = esri_shapefile_driver.Create(
        target_shore_point_vector_path, 0, 0, 0, gdal.GDT_Unknown)
    target_shore_point_layer = target_shore_point_vector.CreateLayer(
        os.path.basename(os.path.splitext(target_shore_point_vector_path)[0]),
        aoi_spatial_reference, ogr.wkbPoint)

    target_shore_point_defn = target_shore_point_layer.GetLayerDefn()

    byte_nodata = 255
    # Create a raster from the AOI extent, plus one pixel in all directions
    # add a pixel buffer so we clip land that's a little outside the grid
    pixel_buffer = 1
    aoi_bounding_box[0] -= pixel_buffer * smallest_feature_size
    aoi_bounding_box[1] -= pixel_buffer * smallest_feature_size
    aoi_bounding_box[2] += pixel_buffer * smallest_feature_size
    aoi_bounding_box[3] += pixel_buffer * smallest_feature_size

    # round up on the rows and cols so that the target raster encloses the
    # base vector
    target_pixel_size = (
        smallest_feature_size / 2.0, -smallest_feature_size / 2.0)  # TODO: why divide by 2?
    n_cols = int(numpy.ceil(
        abs((aoi_bounding_box[2] - aoi_bounding_box[0]) / target_pixel_size[0])))
    n_rows = int(numpy.ceil(
        abs((aoi_bounding_box[3] - aoi_bounding_box[1]) / target_pixel_size[1])))

    driver = gdal.GetDriverByName('GTiff')
    n_bands = 1
    template_raster = driver.Create(
        grid_raster_path, n_cols, n_rows, n_bands, gdal.GDT_Byte)
    template_raster.GetRasterBand(1).SetNoDataValue(byte_nodata)

    # Set the transform based on the upper left corner and given pixel
    # dimensions
    x_source = aoi_bounding_box[0]
    y_source = aoi_bounding_box[3]
    raster_transform = [
        x_source, target_pixel_size[0], 0.0,
        y_source, 0.0, target_pixel_size[1]]
    template_raster.SetGeoTransform(raster_transform)
    template_raster.SetProjection(aoi_spatial_reference.ExportToWkt())

    # Initialize everything to 0
    band = template_raster.GetRasterBand(1)
    band.Fill(0)
    band.FlushCache()
    band = None

    # Make a copy before rasterizing landmass
    # because the all 0s raster is useful for the geomorphology routine
    driver.CreateCopy(land_mask_raster_path, template_raster)
    template_raster = None

    # rasterize landmass to grid
    pygeoprocessing.rasterize(
        landmass_vector_path, land_mask_raster_path, [1], None)

    # grid shoreline from raster
    make_shore_kernel(shore_kernel_path)
    pygeoprocessing.convolve_2d(
        (land_mask_raster_path, 1), (shore_kernel_path, 1),
        convolution_raster_path, target_datatype=gdal.GDT_Byte,
        target_nodata=255)

    # Apply mask to trim off edges of the convolution, which
    # incorrectly categorize as shore.
    pygeoprocessing.mask_raster(
        (convolution_raster_path, 1), aoi_vector_path,
        masked_convolution_raster_path, all_touched=False)

    temp_grid_nodata = pygeoprocessing.get_raster_info(
        land_mask_raster_path)['nodata'][0]

    def _shore_mask_op(shore_convolution):
        """Mask values on land that border water."""
        result = numpy.empty(shore_convolution.shape, dtype=numpy.uint8)
        result[:] = byte_nodata
        valid_mask = shore_convolution != temp_grid_nodata
        # If a pixel is on land, it gets at least a 9, but if it's all on
        # land it gets an 17 (8 neighboring pixels), so we search between 9
        # and 17 to determine a shore pixel
        result[valid_mask] = numpy.where(
            (shore_convolution[valid_mask] >= 9) &
            (shore_convolution[valid_mask] < 17), 1, byte_nodata)
        return result

    pygeoprocessing.raster_calculator(
        [(masked_convolution_raster_path, 1)], _shore_mask_op,
        shore_raster_path, gdal.GDT_Byte, byte_nodata)

    shore_geotransform = pygeoprocessing.get_raster_info(
        shore_raster_path)['geotransform']

    for offset_info, data_block in pygeoprocessing.iterblocks(
            (shore_raster_path, 1)):
        row_indexes, col_indexes = numpy.mgrid[
            offset_info['yoff']:offset_info['yoff']+offset_info['win_ysize'],
            offset_info['xoff']:offset_info['xoff']+offset_info['win_xsize']]
        valid_mask = data_block == 1
        x_coordinates = (
            shore_geotransform[0] +
            shore_geotransform[1] * (col_indexes[valid_mask] + 0.5) +
            shore_geotransform[2] * (row_indexes[valid_mask] + 0.5))
        y_coordinates = (
            shore_geotransform[3] +
            shore_geotransform[4] * (col_indexes[valid_mask] + 0.5) +
            shore_geotransform[5] * (row_indexes[valid_mask] + 0.5))

        for x_coord, y_coord in zip(x_coordinates, y_coordinates):
            # Set the point geometry in the native SRS
            shore_point_geometry = ogr.Geometry(ogr.wkbPoint)
            shore_point_geometry.AddPoint(x_coord, y_coord)
            shore_point_feature = ogr.Feature(target_shore_point_defn)
            shore_point_feature.SetGeometry(shore_point_geometry)

            target_shore_point_layer.CreateFeature(shore_point_feature)
            shore_point_feature = None
    target_shore_point_defn = None
    target_shore_point_layer = None
    target_shore_point_vector = None


def calculate_wave_exposure(
        base_shore_point_vector_path, wwiii_vector_path,
        wwiii_rtree_path, target_wave_exposure_path):
    """Calculate wave exposure for each shore point.
    Join tabular data from Wave Watch 3 to shore points by finding the
    nearest WW3 points to each shore point.

    Parameters:
        wwiii_vector_path (string): path to point shapefile representing
            the Wave Watch III data.
        wwiii_rtree_path (string): path to an rtree index that has
            the points of `wwiii_vector_path` indexed.
    """
    base_vector = gdal.OpenEx(
        base_shore_point_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
    gpkg_driver = gdal.GetDriverByName("GPKG")
    if os.path.exists(target_wave_exposure_path):
        os.remove(target_wave_exposure_path)
    gpkg_driver.CreateCopy(target_wave_exposure_path, base_vector)
    base_vector = None
    points_vector = gdal.OpenEx(
        target_wave_exposure_path, gdal.OF_VECTOR | gdal.GA_Update)
    layer_name = points_vector.GetLayer().GetName()
    points_vector.ExecuteSQL(
        "ALTER TABLE %s RENAME TO 'wave_exposure'" % layer_name)
    points_layer = points_vector.GetLayer()

    wwiii_spatial_reference = osr.SpatialReference()
    wwiii_spatial_reference.ImportFromWkt(
        pygeoprocessing.get_vector_info(wwiii_vector_path)['projection'])

    wwiii_vector = gdal.OpenEx(
        wwiii_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
    wwiii_layer = wwiii_vector.GetLayer()
    wwiii_defn = wwiii_layer.GetLayerDefn()
    field_names = []
    for field_index in range(wwiii_defn.GetFieldCount()):
        field_defn = wwiii_defn.GetFieldDefn(field_index)
        field_name = field_defn.GetName()
        if field_name in ['I', 'J']:
            continue
        field_names.append(field_name)
        points_layer.CreateField(field_defn)
    # points_layer_defn = points_layer.GetLayerDefn()

    points_spatial_reference = osr.SpatialReference()
    points_spatial_reference.ImportFromWkt(
        pygeoprocessing.get_vector_info(target_wave_exposure_path)['projection'])
    points_to_wwiii_transform = osr.CoordinateTransformation(
        points_spatial_reference, wwiii_spatial_reference)
    # rtree index loads without the extension
    wwiii_rtree_base_path = os.path.splitext(
        wwiii_rtree_path)[0]
    wwiii_rtree = rtree.index.Index(wwiii_rtree_base_path)
    wwiii_field_lookup = {}

    LOGGER.info("Interpolating shore points with Wave Watch III data")
    for shore_point_feature in points_layer:
        shore_point_geometry = shore_point_feature.GetGeometryRef()
        
        # Transform each point to match the wwiii SRS
        shore_point_longitude, shore_point_latitude, _ = (
            points_to_wwiii_transform.TransformPoint(
                shore_point_geometry.GetX(), shore_point_geometry.GetY()))
        # get the nearest wave watch III points from the shore point
        nearest_points = list(wwiii_rtree.nearest(
            (shore_point_longitude, shore_point_latitude,
             shore_point_longitude, shore_point_latitude), 3))[0:3]

        # create placeholders for point geometry and field values
        wwiii_points = numpy.empty((3, 2))
        wwiii_values = numpy.empty((3, len(field_names)))
        for fid_index, fid in enumerate(nearest_points):
            wwiii_feature = wwiii_layer.GetFeature(fid)
            wwiii_geometry = wwiii_feature.GetGeometryRef()
            wwiii_points[fid_index] = numpy.array(
                [wwiii_geometry.GetX(), wwiii_geometry.GetY()])
            try:
                wwiii_values[fid_index] = wwiii_field_lookup[fid]
            except KeyError:
                wwiii_field_lookup[fid] = numpy.array(
                    [float(wwiii_feature.GetField(field_name))
                     for field_name in field_names])
                wwiii_values[fid_index] = wwiii_field_lookup[fid]
        distance = numpy.linalg.norm(
            wwiii_points - numpy.array(
                (shore_point_geometry.GetX(),
                 shore_point_geometry.GetY())))
        distance = numpy.linalg.norm(
            wwiii_points - numpy.array(
                (shore_point_longitude,
                 shore_point_latitude)))

        # make sure we're within a valid data distance
        if distance > _MAX_WWIII_DISTANCE:
            continue

        wwiii_values *= distance
        wwiii_values = numpy.mean(wwiii_values, axis=0)
        wwiii_values /= numpy.sum(distance)

        for field_name_index, field_name in enumerate(field_names):
            shore_point_feature.SetField(
                field_name, wwiii_values[field_name_index])
        points_layer.SetFeature(shore_point_feature)
        shore_point_feature = None

    points_layer = None
    points_vector = None
    # LOGGER.info("All done with shore points for grid %s", grid_fid)


def calculate_wind_exposure(
        base_shore_point_vector_path,
        landmass_bounding_rtree_path, landmass_vector_path, workspace_dir,
        smallest_feature_size, max_fetch_distance,
        target_fetch_point_vector_path):
    """Calculate wind exposure for each shore point.

    Parameters:
        base_shore_point_vector_path (string): path to a point shapefile
            representing shore points that should be sampled for wind
            exposure.
        landmass_bounding_rtree_path (string): path to an rtree bounding box
            for the landmass polygons.
        landmass_vector_path (string): path to landmass polygon vetor.
        workspace_dir (string): path to a directory that can be created for
            temporary workspace files
        smallest_feature_size (float): smallest feature size to detect in
            meters.
        max_fetch_distance (float): maximum fetch distance for a ray in
            meters.
        target_fetch_point_vector_path (string): path to target point file,
            will be a copy of `base_shore_point_vector_path`'s geometry with
            an 'REI' (relative exposure index) field added.

    Returns:
        None

    """
    temp_fetch_rays_path = os.path.join(
        workspace_dir, 'fetch_rays.gpkg')

    # this should still match the user-defined SRS from the AOI:
    base_ref_wkt = pygeoprocessing.get_vector_info(
        base_shore_point_vector_path)['projection']
    base_spatial_reference = osr.SpatialReference()
    base_spatial_reference.ImportFromWkt(base_ref_wkt)

    gpkg_driver = gdal.GetDriverByName('GPKG')
    # TODO (maybe): we don't need all the fields copied, but we do need some.
    base_shore_point_vector = gdal.OpenEx(base_shore_point_vector_path, gdal.OF_VECTOR)
    gpkg_driver.CreateCopy(
        target_fetch_point_vector_path, base_shore_point_vector)

    clipped_geometry_shapely_list = []
    temp_utm_clipped_vector = ogr.Open(landmass_vector_path)
    temp_utm_clipped_layer = temp_utm_clipped_vector.GetLayer()
    for tmp_utm_feature in temp_utm_clipped_layer:
        tmp_utm_geometry = tmp_utm_feature.GetGeometryRef()
        shapely_geometry = shapely.wkb.loads(
            tmp_utm_geometry.ExportToWkb())
        if shapely_geometry.is_valid:
            # TODO: if geom is invalid we are just skipping it?
            clipped_geometry_shapely_list.append(shapely_geometry)
        tmp_utm_geometry = None
    temp_utm_clipped_layer = None
    temp_utm_clipped_vector = None
    landmass_shapely = shapely.ops.cascaded_union(
        clipped_geometry_shapely_list)
    clipped_geometry_shapely_list = None

    # load land geometry into shapely object
    landmass_shapely_prep = shapely.prepared.prep(landmass_shapely)

    # explode landmass into lines for easy intersection
    temp_polygon_segements_path = os.path.join(
        workspace_dir, 'polygon_segments.gpkg')
    
    temp_polygon_segments_vector = gpkg_driver.Create(
        temp_polygon_segements_path, 0, 0, 0, gdal.GDT_Unknown)
    temp_polygon_segments_layer = (
        temp_polygon_segments_vector.CreateLayer(
            os.path.splitext(os.path.basename(temp_polygon_segements_path))[0],
            base_spatial_reference, ogr.wkbLineString))
    temp_polygon_segments_defn = temp_polygon_segments_layer.GetLayerDefn()

    polygon_line_rtree = rtree.index.Index()
    polygon_line_index = []
    shapely_line_index = []
    line_id = 0
    for line in geometry_to_lines(landmass_shapely):
        segment_feature = ogr.Feature(temp_polygon_segments_defn)
        segement_geometry = ogr.Geometry(ogr.wkbLineString)
        segement_geometry.AddPoint(*line.coords[0])
        segement_geometry.AddPoint(*line.coords[1])
        segment_feature.SetGeometry(segement_geometry)
        temp_polygon_segments_layer.CreateFeature(segment_feature)

        if (line.bounds[0] == line.bounds[2] and
                line.bounds[1] == line.bounds[3]):
            continue
        polygon_line_rtree.insert(line_id, line.bounds)
        line_id += 1
        polygon_line_index.append(segement_geometry)
        shapely_line_index.append(shapely.wkb.loads(
            segement_geometry.ExportToWkb()))

    temp_polygon_segments_layer.SyncToDisk()
    temp_polygon_segments_layer = None
    temp_polygon_segments_vector = None

    # create fetch rays
    temp_fetch_rays_vector = gpkg_driver.Create(
        temp_fetch_rays_path, 0, 0, 0, gdal.GDT_Unknown)
    temp_fetch_rays_layer = (
        temp_fetch_rays_vector.CreateLayer(
            os.path.splitext(os.path.basename(temp_fetch_rays_path))[0],
            base_spatial_reference, ogr.wkbLineString))
    temp_fetch_rays_defn = temp_fetch_rays_layer.GetLayerDefn()
    temp_fetch_rays_layer.CreateField(ogr.FieldDefn(
        'fetch_dist', ogr.OFTReal))

    target_shore_point_vector = gdal.OpenEx(
        target_fetch_point_vector_path, gdal.OF_VECTOR | gdal.GA_Update)
    target_shore_point_layer = target_shore_point_vector.GetLayer()
    target_shore_point_layer.CreateField(
        ogr.FieldDefn('REI', ogr.OFTReal))
    for ray_index in range(_N_FETCH_RAYS):
        compass_degree = int(ray_index * 360 / 16.)
        target_shore_point_layer.CreateField(
            ogr.FieldDefn('fdist_%d' % compass_degree, ogr.OFTReal))

    shore_point_logger = _make_logger_callback(
        "Wind exposure %.2f%% complete.", LOGGER)
    # Iterate over every shore point
    for shore_point_feature in target_shore_point_layer:
        shore_point_logger(
            float(shore_point_feature.GetFID()) /
            target_shore_point_layer.GetFeatureCount())
        rei_value = 0.0
        # Iterate over every ray direction
        for sample_index in range(_N_FETCH_RAYS):
            compass_degree = int(sample_index * 360 / 16.)
            compass_theta = float(sample_index) / _N_FETCH_RAYS * 360
            rei_pct = shore_point_feature.GetField(
                'REI_PCT%d' % int(compass_theta))
            rei_v = shore_point_feature.GetField(
                'REI_V%d' % int(compass_theta))
            cartesian_theta = -(compass_theta - 90)

            # Determine the direction the ray will point
            delta_x = math.cos(cartesian_theta * math.pi / 180)
            delta_y = math.sin(cartesian_theta * math.pi / 180)

            shore_point_geometry = shore_point_feature.GetGeometryRef()
            point_a_x = (
                shore_point_geometry.GetX() + delta_x * smallest_feature_size)
            point_a_y = (
                shore_point_geometry.GetY() + delta_y * smallest_feature_size)
            point_b_x = point_a_x + delta_x * (
                max_fetch_distance - smallest_feature_size)
            point_b_y = point_a_y + delta_y * (
                max_fetch_distance - smallest_feature_size)
            shore_point_geometry = None

            # build ray geometry so we can intersect it later
            ray_geometry = ogr.Geometry(ogr.wkbLineString)
            ray_geometry.AddPoint(point_a_x, point_a_y)
            ray_geometry.AddPoint(point_b_x, point_b_y)

            # keep a shapely version of the ray so we can do fast intersection
            # with it and the entire landmass
            ray_point_origin_shapely = shapely.geometry.Point(
                point_a_x, point_a_y)

            ray_length = 0.0
            if not landmass_shapely_prep.intersects(
                    ray_point_origin_shapely):
                # the origin is in ocean

                # This algorithm searches for intersections, if one is found
                # the ray updates and a smaller intersection set is determined
                # by experimentation I've found this is significant, but not
                # an order of magnitude, faster than looping through all
                # original possible intersections.  Since this algorithm
                # will be run for a long time, it's worth the additional
                # complexity
                tested_indexes = set()
                while True:
                    intersection = False
                    ray_envelope = ray_geometry.GetEnvelope()
                    for poly_line_index in polygon_line_rtree.intersection(
                            [ray_envelope[i] for i in [0, 2, 1, 3]]):
                        if poly_line_index in tested_indexes:
                            continue
                        tested_indexes.add(poly_line_index)
                        line_segment = (
                            polygon_line_index[poly_line_index])
                        if ray_geometry.Intersects(line_segment):
                            # if the ray intersects the poly line, test if
                            # the intersection is closer than any known
                            # intersection so far
                            intersection_point = ray_geometry.Intersection(
                                line_segment)
                            # offset the dist with smallest_feature_size
                            # update the endpoint of the ray
                            ray_geometry = ogr.Geometry(ogr.wkbLineString)
                            ray_geometry.AddPoint(point_a_x, point_a_y)
                            ray_geometry.AddPoint(
                                intersection_point.GetX(),
                                intersection_point.GetY())
                            intersection = True
                            break
                    if not intersection:
                        break
                # when we get here `min_point` and `ray_length` are the
                # minimum intersection points for the ray and the landmass
                ray_feature = ogr.Feature(temp_fetch_rays_defn)
                ray_length = ray_geometry.Length()
                ray_feature.SetField('fetch_dist', ray_length)
                ray_feature.SetGeometry(ray_geometry)
                temp_fetch_rays_layer.CreateFeature(ray_feature)
            shore_point_feature.SetField(
                'fdist_%d' % compass_degree, ray_length)
            ray_feature = None
            ray_geometry = None
            rei_value += ray_length * rei_pct * rei_v
        shore_point_feature.SetField('REI', rei_value)
        target_shore_point_layer.SetFeature(shore_point_feature)

    target_shore_point_layer.SyncToDisk()
    target_shore_point_layer = None
    target_shore_point_vector = None
    temp_fetch_rays_layer.SyncToDisk()
    temp_fetch_rays_layer = None
    temp_fetch_rays_vector = None


def calculate_relief_exposure(
        base_shore_point_vector_path, global_dem_path, dem_averaging_radius,
        smallest_feature_size, workspace_dir, target_relief_point_vector_path):
    """Calculate DEM relief as average coastal land area within 5km.

    Parameters:
        base_shore_point_vector_path (string):  path to a point shapefile to
            for relief point analysis.
        global_dem_path (string): path to a DEM raster projected in wgs84.
        workspace_dir (string): path to a directory to make local calculations
            in
        target_relief_point_vector_path (string): path to output vector.
            after completion will a value for average relief within 5km in
            a field called 'relief'.

    Returns:
        None.

    """
    # SRS here is inherited from the user's AOI
    base_shore_point_info = pygeoprocessing.get_vector_info(
        base_shore_point_vector_path)
    base_ref_wkt = base_shore_point_info['projection']
    base_spatial_reference = osr.SpatialReference()
    base_spatial_reference.ImportFromWkt(base_ref_wkt)

    shore_point_bounding_box = base_shore_point_info['bounding_box']
    shore_point_bounding_box[0] -= dem_averaging_radius
    shore_point_bounding_box[1] -= dem_averaging_radius
    shore_point_bounding_box[2] += dem_averaging_radius
    shore_point_bounding_box[3] += dem_averaging_radius

    dem_ref_wkt = pygeoprocessing.get_raster_info(global_dem_path)['projection']

    shore_point_clipping_box = pygeoprocessing.transform_bounding_box(
        shore_point_bounding_box, base_ref_wkt,
        dem_ref_wkt, edge_samples=11)

    # TODO: lazily reprojecting to same system as a way to copy on geometry
    pygeoprocessing.reproject_vector(
        base_shore_point_vector_path, base_ref_wkt,
        target_relief_point_vector_path, driver_name='GPKG', copy_fields=False)
    target_relief_point_vector = gdal.OpenEx(
        target_relief_point_vector_path, gdal.OF_VECTOR | gdal.GA_Update)
    target_relief_point_layer = target_relief_point_vector.GetLayer()

    relief_field = ogr.FieldDefn('relief', ogr.OFTReal)
    relief_field.SetPrecision(5)
    relief_field.SetWidth(24)
    target_relief_point_layer.CreateField(relief_field)
    target_relief_point_layer.CreateField(ogr.FieldDefn(
        'id', ogr.OFTInteger))
    for target_feature in target_relief_point_layer:
        target_feature.SetField('id', target_feature.GetFID())
        target_relief_point_layer.SetFeature(target_feature)

    clipped_dem_path = os.path.join(
        workspace_dir, 'clipped_dem.tif')

    target_pixel_size = pygeoprocessing.get_raster_info(
        global_dem_path)['pixel_size']
    # TODO: this warp could also be a mask_raster, maybe
    pygeoprocessing.warp_raster(
        global_dem_path, target_pixel_size, clipped_dem_path,
        'bilinear', target_bb=shore_point_clipping_box)
    clipped_utm_dem_path = os.path.join(
        workspace_dir, 'clipped_utm_dem.tif')
    target_pixel_size = (
        smallest_feature_size / 2.0, -smallest_feature_size / 2.0)
    pygeoprocessing.warp_raster(
        clipped_dem_path, target_pixel_size, clipped_utm_dem_path,
        'bilinear', target_sr_wkt=base_ref_wkt)
    # mask out all DEM < 0 to 0
    nodata = pygeoprocessing.get_raster_info(
        clipped_utm_dem_path)['nodata'][0]

    def zero_negative_values(depth_array):
        valid_mask = depth_array != nodata
        result_array = numpy.empty(
            depth_array.shape, dtype=numpy.int16)
        result_array[:] = nodata
        result_array[valid_mask] = 0
        result_array[depth_array > 0] = depth_array[depth_array > 0]
        return result_array

    positive_dem_path = os.path.join(
        workspace_dir, 'positive_dem.tif')

    pygeoprocessing.raster_calculator(
        [(clipped_utm_dem_path, 1)], zero_negative_values,
        positive_dem_path, gdal.GDT_Int16, nodata)

    # convolve over a user-defined radius
    radius_in_pixels = dem_averaging_radius / target_pixel_size[0]
    kernel_filepath = os.path.join(workspace_dir, 'averaging_kernel.tif')
    create_averaging_kernel_raster(radius_in_pixels, kernel_filepath)

    relief_path = os.path.join(workspace_dir, 'relief.tif')
    pygeoprocessing.convolve_2d(
        (positive_dem_path, 1), (kernel_filepath, 1),
        relief_path, ignore_nodata=True)

    relief_raster = gdal.Open(relief_path)
    relief_band = relief_raster.GetRasterBand(1)
    n_rows = relief_band.YSize
    relief_geotransform = relief_raster.GetGeoTransform()
    target_relief_point_layer.ResetReading()
    for point_feature in target_relief_point_layer:
        point_geometry = point_feature.GetGeometryRef()
        point_x, point_y = point_geometry.GetX(), point_geometry.GetY()
        point_geometry = None

        pixel_x = int(
            (point_x - relief_geotransform[0]) / relief_geotransform[1])
        pixel_y = int(
            (point_y - relief_geotransform[3]) / relief_geotransform[5])

        if pixel_y >= n_rows:
            pixel_y = n_rows - 1
        try:
            pixel_value = relief_band.ReadAsArray(
                xoff=pixel_x, yoff=pixel_y, win_xsize=1,
                win_ysize=1)[0, 0]
        except Exception:
            LOGGER.error(
                'relief_band size %d %d', relief_band.XSize,
                relief_band.YSize)
            raise
        point_feature.SetField('relief', float(pixel_value))
        target_relief_point_layer.SetFeature(point_feature)

    target_relief_point_layer.SyncToDisk()
    target_relief_point_layer = None
    target_relief_point_vector = None


def _extract_raster_values_by_points(
        base_point_vector_path, base_raster_path, target_pickle_path):

    vector = gdal.OpenEx(
        base_point_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
    layer = vector.GetLayer()

    raster = gdal.Open(base_raster_path)
    band = raster.GetRasterBand(1)
    n_rows = band.YSize
    result = {}
    raster_geotransform = raster.GetGeoTransform()
    for point_feature in layer:
        point_geometry = point_feature.GetGeometryRef()
        point_x, point_y = point_geometry.GetX(), point_geometry.GetY()
        point_fid = point_feature.GetFID()
        point_geometry = None
        pixel_x = int(
            (point_x - raster_geotransform[0]) / raster_geotransform[1])
        pixel_y = int(
            (point_y - raster_geotransform[3]) / raster_geotransform[5])

        if pixel_y >= n_rows:
            pixel_y = n_rows - 1
        try:
            pixel_value = band.ReadAsArray(
                xoff=pixel_x, yoff=pixel_y, win_xsize=1,
                win_ysize=1)[0, 0]
        except Exception:
            LOGGER.error(
                'relief_band size %d %d', band.XSize, band.YSize)
            raise
        result[point_fid] = pixel_value
    with open(target_pickle_path, 'wb') as pickle_file:
        pickle.dump(result, pickle_file)


def calculate_habitat_protection(
        base_shore_point_vector_path,
        habitat_table_path, workspace_dir,
        target_habitat_protection_path):
    """Calculate habitat protection at a set of points.

    Mandate that habitat layers use the same projected SRS as AOI. We won't 
    reproject anything here. 

    Parameters:
        base_shore_point_vector_path (string):  path to a point shapefile to
            analyze habitat protection at.
        habitat_layer_lookup: a dictionary mapping habitat id to a
            (path, rank, distance) tuple
        workspace_dir (string): path to a directory to make local calculations
            in
        target_habitat_protection_point_vector_path (string): path to desired
            output vector.  after completion will have a rank for each
            habitat ID, and a field called Rhab with a value from 1-5
            indicating relative level of protection of that point.

    Returns:
        None.

    """

    habitat_dataframe = (pandas.read_csv(
        habitat_table_path, header=0,
        dtype={'habitat': str, 'path': str, 'rank': numpy.int16,
               'protection distance (m)': numpy.int16})
        .rename(columns={'protection distance (m)': 'distance'}))

    # SRS here is inherited from the user's AOI
    base_shore_point_info = pygeoprocessing.get_vector_info(
        base_shore_point_vector_path)
    base_ref_wkt = base_shore_point_info['projection']
    base_spatial_reference = osr.SpatialReference()
    base_spatial_reference.ImportFromWkt(base_ref_wkt)

    max_habitat_search_distance = habitat_dataframe['distance'].max()
    shore_point_bounding_box = base_shore_point_info['bounding_box']
    shore_point_bounding_box[0] -= max_habitat_search_distance
    shore_point_bounding_box[1] -= max_habitat_search_distance
    shore_point_bounding_box[2] += max_habitat_search_distance
    shore_point_bounding_box[3] += max_habitat_search_distance
    shore_point_clipping_shapely = shapely.geometry.box(*shore_point_bounding_box)

    habitat_shapely_lookup = {}
    for habitat_row in habitat_dataframe.itertuples():
        habitat_vector = gdal.OpenEx(
            _sanitize_path(habitat_table_path, habitat_row.path),
            gdal.OF_VECTOR | gdal.GA_ReadOnly)
        habitat_layer = habitat_vector.GetLayer()

        # this will hold the clipped habitat geometry
        gpkg_driver = gdal.GetDriverByName("GPKG")
        temp_clipped_vector_path = os.path.join(
            workspace_dir, 'clipped_habitat_%s.gpkg' % habitat_row.id)
        utm_clipped_vector_path = os.path.join(
            workspace_dir, 'utm_clipped_habitat_%s.gpkg' % habitat_row.id)
        for path in [temp_clipped_vector_path, utm_clipped_vector_path]:
            if os.path.exists(path):
                os.remove(path)
        temp_clipped_vector = gpkg_driver.Create(
            temp_clipped_vector_path, 0, 0, 0, gdal.GDT_Unknown)
        temp_clipped_layer = (
            temp_clipped_vector.CreateLayer(
                os.path.basename(os.path.splitext(temp_clipped_vector_path)[0]),
                base_spatial_reference, ogr.wkbPolygon))
        temp_clipped_defn = temp_clipped_layer.GetLayerDefn()

        # clip global polygon to global clipping box
        clipped_geometry_shapely_list = []
        for habitat_feature in habitat_layer:
            habitat_shapely = shapely.wkb.loads(
                habitat_feature.GetGeometryRef().ExportToWkb())
            intersection_shapely = shore_point_clipping_shapely.intersection(
                habitat_shapely)
            if intersection_shapely.is_empty:
                continue
            try:
                # if shapely_geometry.is_valid:
                clipped_geometry_shapely_list.append(intersection_shapely)
                clipped_geometry = ogr.CreateGeometryFromWkt(
                    intersection_shapely.wkt)
                clipped_feature = ogr.Feature(temp_clipped_defn)
                clipped_feature.SetGeometry(clipped_geometry)
                temp_clipped_layer.CreateFeature(clipped_feature)
                clipped_feature = None
            except Exception:
                LOGGER.warn(
                    "Couldn't process this intersection %s",
                    intersection_shapely)

        habitat_shapely_lookup[habitat_row.id] = shapely.ops.cascaded_union(
            clipped_geometry_shapely_list)
        temp_clipped_layer.SyncToDisk()
        temp_clipped_layer = None
        temp_clipped_vector = None
        habitat_vector = None
        habitat_layer = None

    base_shore_point_vector = gdal.OpenEx(
        base_shore_point_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
    base_shore_point_layer = base_shore_point_vector.GetLayer()

    point_habitat_rank_lookup = {}  # {0: {'kelp': 4, 'eelgrass': 3}}
    for target_feature in base_shore_point_layer:
        target_feature_geometry = (
            target_feature.GetGeometryRef().Clone())
        target_feature_shapely = shapely.wkb.loads(
            target_feature_geometry.ExportToWkb())
        fid = target_feature.GetFID()
        point_habitat_rank_lookup[fid] = {}

        for habitat_row in habitat_dataframe.itertuples():
            point_habitat_rank = 5  # represents no habitat protection
            if habitat_shapely_lookup[habitat_row.id].is_empty:
                # TODO: how to actually handle this case of no geom in a habitat layer?
                # it's quite unlikely...
                continue
            point_distance_to_feature = target_feature_shapely.distance(
                habitat_shapely_lookup[habitat_row.id])
            if point_distance_to_feature <= habitat_row.distance:
                point_habitat_rank = habitat_row.rank
            point_habitat_rank_lookup[fid][habitat_row.id] = point_habitat_rank

    habitat_ranks_dataframe = pandas.DataFrame.from_dict(
        point_habitat_rank_lookup, orient='index')

    def _calc_Rhab(row):
        # Equation 4
        sum_sq_rank = 0.0
        min_rank = 5
        for r in row:
            if r < min_rank:
                min_rank = r
            sum_sq_rank += (5 - r)**2

        if sum_sq_rank > 0:
            r_hab_val = max(
                1.0, 4.8 - 0.5 * (
                    (1.5 * (5-min_rank))**2 + sum_sq_rank -
                    (5-min_rank)**2)**0.5)
        else:
            r_hab_val = 5.0
        return r_hab_val

    habitat_ranks_dataframe['Rhab'] = habitat_ranks_dataframe.apply(
        axis=1, func=_calc_Rhab)
    habitat_ranks_dataframe.to_csv(target_habitat_protection_path)


def calculate_geomorphology_exposure(
        geomorphology_vector_path, grid_raster_path, working_dir,
        target_geomorphology_raster_path, base_shore_point_vector_path,
        target_pickle_path):

    vector = gdal.OpenEx(geomorphology_vector_path)
    # TODO: what happens if we select for a rank not present in shp?
    acceptable_ranks = (1, 2, 3, 4, 5)
    nodata_value = 3 #  TODO: ask if it's acceptable to use 3 when geomorph data is missing

    template_raster = gdal.OpenEx(grid_raster_path, gdal.OF_RASTER)
    driver = gdal.GetDriverByName('GTiff')
    driver.CreateCopy(target_geomorphology_raster_path, template_raster)
    template_raster = None
    target_geomorphology_raster = gdal.OpenEx(
        target_geomorphology_raster_path, gdal.OF_RASTER | gdal.GA_Update)
    band = target_geomorphology_raster.GetRasterBand(1)
    band.Fill(nodata_value)
    band.SetNoDataValue(nodata_value)
    band.FlushCache()
    band = None
    target_geomorphology_raster = None

    geomorphology_raster_path_band_list = []
    for rank in acceptable_ranks:
        layer = vector.GetLayer()
        filter_string = ('RANK = %d' % rank)
        layer.SetAttributeFilter(str(filter_string))
        target_raster_path = os.path.join(
            working_dir, 'geomorphology_rank_%d.tif' % rank)
        geomorphology_raster_path_band_list.append((target_raster_path, 1))
        _rasterize_vector_onto_base(
            target_geomorphology_raster_path, geomorphology_vector_path,
            'RANK', target_raster_path, filter_string=filter_string)
        layer = None

    def _min_op(*r1):
        return numpy.amin(r1, axis=0)

    pygeoprocessing.raster_calculator(
        geomorphology_raster_path_band_list,
        _min_op, target_geomorphology_raster_path,
        gdal.GDT_Byte, nodata_value)

    _extract_raster_values_by_points(
        base_shore_point_vector_path, target_geomorphology_raster_path,
        target_pickle_path)




def _rasterize_vector_onto_base(
        base_raster_path, base_vector_path, attribute_id,
        target_raster_path, filter_string=None):
    """Rasterize attribute from vector onto a copy of base.

    Parameters:
        base_raster_path (string): path to a base raster file
        attribute_id (string): id in `base_vector_path` to rasterize.
        target_raster_path (string): a copy of `base_raster_path` with
            `base_vector_path[attribute_id]` rasterized on top.
        filter_string (string): filtering string to select from farm layer

    Returns:
        None.
    """
    base_raster = gdal.OpenEx(base_raster_path, gdal.OF_RASTER)
    raster_driver = gdal.GetDriverByName('GTiff')
    target_raster = raster_driver.CreateCopy(target_raster_path, base_raster)
    base_raster = None

    vector = gdal.OpenEx(base_vector_path)
    layer = vector.GetLayer()

    if filter_string is not None:
        layer.SetAttributeFilter(str(filter_string))
    gdal.RasterizeLayer(
        target_raster, [1], layer,
        options=['ATTRIBUTE=%s' % attribute_id])
    target_raster.FlushCache()
    target_raster = None
    layer = None
    vector = None


def build_wwiii_rtree(wwiii_vector_path, wwiii_rtree_path):
    """Build RTree indexed by FID for points in `wwwiii_vector_path`."""
    base_wwiii_rtree_path = os.path.splitext(wwiii_rtree_path)[0]
    if os.path.exists(wwiii_rtree_path):
        for ext in ['.dat', '.idx']:
            os.remove(base_wwiii_rtree_path+ext)
    wwiii_rtree = rtree.index.Index(base_wwiii_rtree_path)

    wwiii_vector = gdal.OpenEx(wwiii_vector_path, gdal.OF_VECTOR)
    wwiii_layer = wwiii_vector.GetLayer()
    for wwiii_feature in wwiii_layer:
        wwiii_geometry = wwiii_feature.GetGeometryRef()
        wwiii_x = wwiii_geometry.GetX()
        wwiii_y = wwiii_geometry.GetY()
        wwiii_rtree.insert(
            wwiii_feature.GetFID(), (wwiii_x, wwiii_y, wwiii_x, wwiii_y))
    wwiii_layer = None
    wwiii_vector = None


def build_feature_bounding_box_rtree(vector_path, target_rtree_path):
    """Build an r-tree index of the global feature envelopes.

    Parameter:
        vector_path (string): path to vector to build bounding box index for
        target_rtree_path (string): path to ".dat" file to store the saved
            r-tree.  A ValueError is raised if this file already exists

    Returns:
        None.

    """
    # the input path has a .dat extension, but the `rtree` package only uses
    # the basename.  It's a quirk of the library, so we'll deal with it by
    # cutting off the extension.
    global_feature_index_base = os.path.splitext(
        target_rtree_path)[0]
    LOGGER.info("Building rtree index at %s", global_feature_index_base)
    if os.path.exists(target_rtree_path):
        for ext in ['.dat', '.idx']:
            os.remove(global_feature_index_base + ext)
    global_feature_index = rtree.index.Index(global_feature_index_base)

    global_vector = gdal.OpenEx(vector_path, gdal.OF_VECTOR)
    global_layer = global_vector.GetLayer()
    n_features = global_layer.GetFeatureCount()

    logger_callback = _make_logger_callback(
        'rTree construction %.2f%% complete', LOGGER)

    for feature_index, global_feature in enumerate(global_layer):
        feature_geometry = global_feature.GetGeometryRef()
        # format of envelope is [minx, maxx, miny, maxy]
        feature_envelope = feature_geometry.GetEnvelope()
        # format of tree bounding box is [minx, miny, maxx, maxy]
        global_feature_index.insert(
            global_feature.GetFID(), (
                feature_envelope[0], feature_envelope[2],
                feature_envelope[1], feature_envelope[3]))
        logger_callback(float(feature_index) / n_features)
    global_feature_index.close()


def make_shore_kernel(kernel_path):
    """Make a 3x3 raster with a 9 in the middle and 1s on the outside."""
    driver = gdal.GetDriverByName('GTiff')
    kernel_raster = driver.Create(
        kernel_path.encode('utf-8'), 3, 3, 1,
        gdal.GDT_Byte)

    # Make some kind of geotransform, it doesn't matter what but
    # will make GIS libraries behave better if it's all defined
    kernel_raster.SetGeoTransform([0, 1, 0, 0, 0, -1])
    srs = osr.SpatialReference()
    srs.SetWellKnownGeogCS('WGS84')
    kernel_raster.SetProjection(srs.ExportToWkt())

    kernel_band = kernel_raster.GetRasterBand(1)
    kernel_band.SetNoDataValue(127)
    kernel_band.WriteArray(numpy.array([[1, 1, 1], [1, 9, 1], [1, 1, 1]]))


def create_averaging_kernel_raster(radius_in_pixels, kernel_filepath):
    """Create a raster kernel with a radius given.

    Parameters:
        expected_distance (int or float): The distance (in pixels) of the
            kernel's radius, the distance at which the value of the decay
            function is equal to `1/e`.
        kernel_filepath (string): The path to the file on disk where this
            kernel should be stored.  If this file exists, it will be
            overwritten.

    Returns:
        None

    """
    driver = gdal.GetDriverByName('GTiff')
    kernel_dataset = driver.Create(
        kernel_filepath.encode('utf-8'), int(radius_in_pixels)*2+1,
        int(radius_in_pixels)*2+1,
        1, gdal.GDT_Float32, options=[
            'BIGTIFF=IF_SAFER', 'TILED=YES', 'BLOCKXSIZE=256',
            'BLOCKYSIZE=256'])

    # Make some kind of geotransform, it doesn't matter what but
    # will make GIS libraries behave better if it's all defined
    kernel_dataset.SetGeoTransform([444720, 30, 0, 3751320, 0, -30])
    srs = osr.SpatialReference()
    srs.SetUTM(11, 1)
    srs.SetWellKnownGeogCS('NAD27')
    kernel_dataset.SetProjection(srs.ExportToWkt())

    kernel_band = kernel_dataset.GetRasterBand(1)
    kernel_band.SetNoDataValue(-9999)

    cols_per_block, rows_per_block = kernel_band.GetBlockSize()

    n_cols = kernel_dataset.RasterXSize
    n_rows = kernel_dataset.RasterYSize

    n_col_blocks = int(math.ceil(n_cols / float(cols_per_block)))
    n_row_blocks = int(math.ceil(n_rows / float(rows_per_block)))

    integration = 0.0
    for row_block_index in range(n_row_blocks):
        row_offset = row_block_index * rows_per_block
        row_block_width = n_rows - row_offset
        if row_block_width > rows_per_block:
            row_block_width = rows_per_block

        for col_block_index in range(n_col_blocks):
            col_offset = col_block_index * cols_per_block
            col_block_width = n_cols - col_offset
            if col_block_width > cols_per_block:
                col_block_width = cols_per_block

            # Numpy creates index rasters as ints by default, which sometimes
            # creates problems on 32-bit builds when we try to add Int32
            # matrices to float64 matrices.
            row_indices, col_indices = numpy.indices((row_block_width,
                                                      col_block_width),
                                                     dtype=numpy.float)

            row_indices += numpy.float(row_offset - radius_in_pixels)
            col_indices += numpy.float(col_offset - radius_in_pixels)

            kernel_index_distances = numpy.hypot(
                row_indices, col_indices)
            kernel = numpy.where(
                kernel_index_distances > radius_in_pixels, 0.0, 1.0)
            integration += numpy.sum(kernel)

            kernel_band.WriteArray(kernel, xoff=col_offset,
                                   yoff=row_offset)

    # Need to flush the kernel's cache to disk before opening up a new Dataset
    # object in interblocks()
    kernel_dataset.FlushCache()

    for block_data, kernel_block in pygeoprocessing.iterblocks(
            (kernel_filepath, 1)):
        kernel_block /= integration
        kernel_band.WriteArray(kernel_block, xoff=block_data['xoff'],
                               yoff=block_data['yoff'])



def geometry_to_lines(geometry):
    """Convert a geometry object to a list of lines."""
    if geometry.type == 'Polygon':
        return polygon_to_lines(geometry)
    elif geometry.type == 'MultiPolygon':
        line_list = []
        for geom in geometry.geoms:
            line_list.extend(geometry_to_lines(geom))
        return line_list
    else:
        return []


def polygon_to_lines(geometry):
    """Return a list of shapely lines given higher order shapely geometry."""
    line_list = []
    last_point = geometry.exterior.coords[0]
    for point in geometry.exterior.coords[1::]:
        if point == last_point:
            continue
        line_list.append(shapely.geometry.LineString([last_point, point]))
        last_point = point
    line_list.append(shapely.geometry.LineString([
        last_point, geometry.exterior.coords[0]]))
    for interior in geometry.interiors:
        last_point = interior.coords[0]
        for point in interior.coords[1::]:
            if point == last_point:
                continue
            line_list.append(shapely.geometry.LineString([last_point, point]))
            last_point = point
        line_list.append(shapely.geometry.LineString([
            last_point, interior.coords[0]]))
    return line_list


def _sanitize_path(base_path, raw_path):
    """Return `path` if absolute, or make absolute local to `base_path`."""
    if os.path.isabs(raw_path):
        return raw_path
    else:  # assume relative path w.r.t. the response table
        return os.path.join(os.path.dirname(base_path), raw_path)


def _make_logger_callback(message, logger):
    """Build a timed logger callback that prints `message` replaced.

    Parameters:
        message (string): a string that expects a %f replacement variable for
            `proportion_complete`.

    Returns:
        Function with signature:
            logger_callback(proportion_complete, psz_message, p_progress_arg)

    """
    def logger_callback(proportion_complete):
        """Argument names come from the GDAL API for callbacks."""
        try:
            current_time = time.time()
            if ((current_time - logger_callback.last_time) > 5.0 or
                    (proportion_complete == 1.0 and
                     logger_callback.total_time >= 5.0)):
                LOGGER.info(message, proportion_complete * 100)
                logger_callback.last_time = current_time
                logger_callback.total_time += current_time
        except AttributeError:
            logger_callback.last_time = time.time()
            logger_callback.total_time = 0.0

    return logger_callback